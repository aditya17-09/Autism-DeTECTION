{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bff6493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c56955d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>Class</th>\n",
       "      <th>src</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Saudi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Saudi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Saudi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Saudi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Saudi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  Class    src\n",
       "0   0   0   0   0   0   1   1   1   0    0      0  Saudi\n",
       "1   0   0   1   0   1   0   0   1   0    0      0  Saudi\n",
       "2   0   0   0   0   0   0   1   0   0    0      0  Saudi\n",
       "3   0   0   0   0   0   0   0   0   0    0      0  Saudi\n",
       "4   0   0   0   0   0   0   0   0   0    0      0  Saudi"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the csv file with pandas\n",
    "df = pd.read_csv('./Downloads/merged_saudi_github_thabtah_toddler_child.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fde17d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2566, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a930214",
   "metadata": {},
   "source": [
    "the dataset has 2566 rows and 12 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60c59e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Class',\n",
       "       'src'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "082bdb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2566 entries, 0 to 2565\n",
      "Data columns (total 12 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   A1      2566 non-null   int64 \n",
      " 1   A2      2566 non-null   int64 \n",
      " 2   A3      2566 non-null   int64 \n",
      " 3   A4      2566 non-null   int64 \n",
      " 4   A5      2566 non-null   int64 \n",
      " 5   A6      2566 non-null   int64 \n",
      " 6   A7      2566 non-null   int64 \n",
      " 7   A8      2566 non-null   int64 \n",
      " 8   A9      2566 non-null   int64 \n",
      " 9   A10     2566 non-null   int64 \n",
      " 10  Class   2566 non-null   int64 \n",
      " 11  src     2566 non-null   object\n",
      "dtypes: int64(11), object(1)\n",
      "memory usage: 240.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58a0a9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2566.000000</td>\n",
       "      <td>2566.000000</td>\n",
       "      <td>2566.000000</td>\n",
       "      <td>2566.000000</td>\n",
       "      <td>2566.000000</td>\n",
       "      <td>2566.000000</td>\n",
       "      <td>2566.000000</td>\n",
       "      <td>2566.000000</td>\n",
       "      <td>2566.000000</td>\n",
       "      <td>2566.000000</td>\n",
       "      <td>2566.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.563133</td>\n",
       "      <td>0.461808</td>\n",
       "      <td>0.460249</td>\n",
       "      <td>0.516758</td>\n",
       "      <td>0.552221</td>\n",
       "      <td>0.577942</td>\n",
       "      <td>0.623149</td>\n",
       "      <td>0.483632</td>\n",
       "      <td>0.491037</td>\n",
       "      <td>0.607171</td>\n",
       "      <td>0.657054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.496095</td>\n",
       "      <td>0.498636</td>\n",
       "      <td>0.498515</td>\n",
       "      <td>0.499817</td>\n",
       "      <td>0.497362</td>\n",
       "      <td>0.493984</td>\n",
       "      <td>0.484692</td>\n",
       "      <td>0.499829</td>\n",
       "      <td>0.500017</td>\n",
       "      <td>0.488475</td>\n",
       "      <td>0.474786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                A1           A2           A3           A4           A5  \\\n",
       "count  2566.000000  2566.000000  2566.000000  2566.000000  2566.000000   \n",
       "mean      0.563133     0.461808     0.460249     0.516758     0.552221   \n",
       "std       0.496095     0.498636     0.498515     0.499817     0.497362   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       1.000000     0.000000     0.000000     1.000000     1.000000   \n",
       "75%       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                A6           A7           A8           A9          A10  \\\n",
       "count  2566.000000  2566.000000  2566.000000  2566.000000  2566.000000   \n",
       "mean      0.577942     0.623149     0.483632     0.491037     0.607171   \n",
       "std       0.493984     0.484692     0.499829     0.500017     0.488475   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       1.000000     1.000000     0.000000     0.000000     1.000000   \n",
       "75%       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "             Class  \n",
       "count  2566.000000  \n",
       "mean      0.657054  \n",
       "std       0.474786  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       1.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ba59234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1       2\n",
       "A2       2\n",
       "A3       2\n",
       "A4       2\n",
       "A5       2\n",
       "A6       2\n",
       "A7       2\n",
       "A8       2\n",
       "A9       2\n",
       "A10      2\n",
       "Class    2\n",
       "src      4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199d3b4e",
   "metadata": {},
   "source": [
    "Attributes:\n",
    "\n",
    "A1-A10: Items within Q-Chat-10  in which questions possible answers : “Always, Usually, Sometimes, Rarly & Never” items’ values are mapped to “1” or “0” in the dataset. For questions 1-9 (A1-A9) in Q-chat-10,  if the respose was  Sometimes / Rarly / Never “1” is assigned to the question (A1-A9). However, for question 10 (A10), if the respose was Always / Usually / Sometimes then “1” is assigned to that question. If the user obtained More than 3 Add points together for all ten questions. If your child scores more than 3 (Q-chat-10- score) then there is a potential ASD traits otherwise no ASD traits are observed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aa79b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1686\n",
       "0     880\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a98a58",
   "metadata": {},
   "source": [
    "DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a216300c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1       0\n",
       "A2       0\n",
       "A3       0\n",
       "A4       0\n",
       "A5       0\n",
       "A6       0\n",
       "A7       0\n",
       "A8       0\n",
       "A9       0\n",
       "A10      0\n",
       "Class    0\n",
       "src      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f66f89",
   "metadata": {},
   "source": [
    "THE DATASET HAS NO MISSING VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80ec9324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2566 entries, 0 to 2565\n",
      "Data columns (total 12 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   A1      2566 non-null   int64 \n",
      " 1   A2      2566 non-null   int64 \n",
      " 2   A3      2566 non-null   int64 \n",
      " 3   A4      2566 non-null   int64 \n",
      " 4   A5      2566 non-null   int64 \n",
      " 5   A6      2566 non-null   int64 \n",
      " 6   A7      2566 non-null   int64 \n",
      " 7   A8      2566 non-null   int64 \n",
      " 8   A9      2566 non-null   int64 \n",
      " 9   A10     2566 non-null   int64 \n",
      " 10  Class   2566 non-null   int64 \n",
      " 11  src     2566 non-null   object\n",
      "dtypes: int64(11), object(1)\n",
      "memory usage: 240.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5b1a715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "thabtah_toddler    1054\n",
       "github              714\n",
       "Saudi               506\n",
       "UCI_child           292\n",
       "Name: src, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['src'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3514539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df['src'] = encoder.fit_transform(df['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "952344bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12345)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3689ef2",
   "metadata": {},
   "source": [
    "MODEL TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c126f292",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f8b5828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9377431906614786\n",
      "Confusion matrix: \n",
      " [[150  19]\n",
      " [ 13 332]]\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "log_reg_model = LogisticRegression()\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = log_reg_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", acc)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix: \\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "759f6fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90       169\n",
      "           1       0.95      0.96      0.95       345\n",
      "\n",
      "    accuracy                           0.94       514\n",
      "   macro avg       0.93      0.92      0.93       514\n",
      "weighted avg       0.94      0.94      0.94       514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1284784e",
   "metadata": {},
   "source": [
    "SUPPORT VECTOR MACHINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b01f929c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9610894941634242\n",
      "Confusion matrix: \n",
      " [[156  13]\n",
      " [  7 338]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_model = SVC()\n",
    "svc_model.fit(X_train,y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = svc_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", acc)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix: \\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ea00fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94       169\n",
      "           1       0.96      0.98      0.97       345\n",
      "\n",
      "    accuracy                           0.96       514\n",
      "   macro avg       0.96      0.95      0.96       514\n",
      "weighted avg       0.96      0.96      0.96       514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812d1f71",
   "metadata": {},
   "source": [
    "K-NEAREST NEIGHBOURS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c71c8bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9182879377431906\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Train the KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = knn_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0302182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       169\n",
      "           1       0.95      0.92      0.94       345\n",
      "\n",
      "    accuracy                           0.92       514\n",
      "   macro avg       0.90      0.92      0.91       514\n",
      "weighted avg       0.92      0.92      0.92       514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98f8f60",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9b08059",
   "metadata": {},
   "source": [
    "HYPER PARAMETER TUNING WITH RANDOMIZED SEARCH CV TO GET BETTER RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882dc2cf",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f117a543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'warm_start': False, 'solver': 'newton-cg', 'penalty': 'l2', 'max_iter': 100, 'fit_intercept': True, 'C': 0.03359818286283781}\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for Randomized Search\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C': np.logspace(-4, 4, 20),\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'max_iter': [100, 1000, 10000, 100000],\n",
    "    'fit_intercept': [True, False],\n",
    "    'warm_start': [True, False]\n",
    "}\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Perform Randomized Search with Cross Validation\n",
    "rand_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=100, cv=10, n_jobs=-1, random_state=12345)\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = rand_search.best_params_\n",
    "print(best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "491771c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[148  21]\n",
      " [ 10 335]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91       169\n",
      "           1       0.94      0.97      0.96       345\n",
      "\n",
      "    accuracy                           0.94       514\n",
      "   macro avg       0.94      0.92      0.93       514\n",
      "weighted avg       0.94      0.94      0.94       514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model with the best hyperparameters\n",
    "model = LogisticRegression(**best_params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using Confusion Matrix and Classification Report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc6ea3c",
   "metadata": {},
   "source": [
    "SUPPORT VECTOR MACHINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a43fe464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[166   3]\n",
      " [  4 341]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       169\n",
      "           1       0.99      0.99      0.99       345\n",
      "\n",
      "    accuracy                           0.99       514\n",
      "   macro avg       0.98      0.99      0.98       514\n",
      "weighted avg       0.99      0.99      0.99       514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    \"C\": np.logspace(-3, 3, 7),\n",
    "    \"gamma\": np.logspace(-3, 3, 7),\n",
    "    \"kernel\": [\"linear\", \"rbf\"]\n",
    "}\n",
    "\n",
    "# create a SVC classifier\n",
    "svc = SVC()\n",
    "\n",
    "# use RandomizedSearchCV to perform hyperparameter tuning\n",
    "random_search = RandomizedSearchCV(svc, param_grid, n_iter=100, cv=10, scoring=\"accuracy\", verbose=0, n_jobs=-1)\n",
    "\n",
    "# fit the RandomizedSearchCV object to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# predict on the test set\n",
    "y_pred = random_search.predict(X_test)\n",
    "\n",
    "# evaluate the model using confusion matrix and classification report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758ea053",
   "metadata": {},
   "source": [
    "K- NEAREST NEIGHBOURS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d514dd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[158  11]\n",
      " [ 11 334]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       169\n",
      "           1       0.97      0.97      0.97       345\n",
      "\n",
      "    accuracy                           0.96       514\n",
      "   macro avg       0.95      0.95      0.95       514\n",
      "weighted avg       0.96      0.96      0.96       514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    \"n_neighbors\": np.arange(1, 31),\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"metric\": [\"euclidean\", \"manhattan\"]\n",
    "}\n",
    "\n",
    "# create a KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# use RandomizedSearchCV to perform hyperparameter tuning\n",
    "random_search = RandomizedSearchCV(knn, param_grid, n_iter=100, cv=10, scoring=\"accuracy\", verbose=0, n_jobs=-1)\n",
    "\n",
    "# fit the RandomizedSearchCV object to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# predict on the test set\n",
    "y_pred = random_search.predict(X_test)\n",
    "\n",
    "# evaluate the model using confusion matrix and classification report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e4bed6",
   "metadata": {},
   "source": [
    "CONCLUSION:\n",
    "\n",
    "BEST MODEL SO FAR AFTER TUNING PARAMETERS IS SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addc9f54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
